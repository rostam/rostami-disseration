\PassOptionsToPackage{dvipsnames}{xcolor} % prevent an option clash
\documentclass{beamer}
\usetheme{Ilmenau}

\usepackage{listings}
\usepackage{amsmath}
\usepackage{sidecap}
\usepackage{graphicx}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{etoolbox}
\usepackage{parskip}
\usepackage{setspace}
\newcommand{\col}{\ensuremath{c}}
\newcommand{\row}{\ensuremath{r}}
\newcommand{\vek}[1]{{\ensuremath{\mathbf #1}}}
\newcommand{\figref}[1]{Fig.~\protect\ref{#1}}
\newcommand{\secref}[1]{Sect.~\protect\ref{#1}}
\newcommand{\R}{\ensuremath{\field{R}}}
\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\sparsifysymbol}{\ensuremath{\rho}}
\newcommand{\sparsify}[1]{\ensuremath{\sparsifysymbol(#1)}}
\newcommand{\todo}[1]{\textbf{#1}}
\newcommand{\nnz}[1]{\ensuremath{\operatorname{nz}(#1)}}

\hyphenation{
	MATLAB
}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\nreq}{L}
\newcommand{\req}{M}
\newcommand{\setR}{\ensuremath{\mathbb{R}}}
\lstdefinelanguage{JavaScript}{
keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, while, do, else, case, break,for,with},
basicstyle=\ttfamily,
keywordstyle=\bfseries,
ndkeywords={class, export, boolean, throw, implements, import},
ndkeywordstyle=\color{darkgray}\bfseries,
identifierstyle=\color{black},
sensitive=false,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{purple}\ttfamily,
stringstyle=\color{red}\ttfamily,
morestring=[b]',
morestring=[b]"
}

\lstset{
language=JavaScript,
backgroundcolor=\color{lightgray},
extendedchars=true,
basicstyle=\footnotesize\ttfamily,
showstringspaces=false,
showspaces=false,
numbers=left,
numberstyle=\footnotesize,
numbersep=9pt,
tabsize=2,
breaklines=true,
showtabs=false,
captionpos=b
keywords={with},
}

% Define the name of the two minimization problems
\newcommand{\MinStaBic}{\textsc{MinimumStarBicoloring}}
\newcommand{\MinBidCom}{\textsc{MinimumBidirectionalCompression}}

\usepackage[dvipsnames]{xcolor}% http://ctan.org/pkg/xcolor
\usepackage{algcompatible}% http://ctan.org/pkg/algorithmicx

\definecolor{beamer@blendedblue}{rgb}{0.3,0.5,0.3} % changed this
\makeatletter
\newcommand{\algcolor}[2]{%
  \hskip-\ALG@thistlm\colorbox{#1}{\parbox{\dimexpr\linewidth-2\fboxsep}{\hskip\ALG@thistlm\relax #2}}%
}
\newcommand{\algemphg}[1]{\algcolor{Green}{#1}}
\newcommand{\algemphr}[1]{\algcolor{Red}{#1}}
\newcommand{\algemphb}[1]{\algcolor{Turquoise}{#1}}


\newcommand{\LINEIF}[2]{%
    \STATE\algorithmicif\ {#1}\ \algorithmicdo\ {#2}\ \algorithmicend\ \algorithmicif%
}
\makeatother
% items enclosed in square brackets are optional; explanation below
\title[]
{Combining partial Jacobian computation and preconditioning}
\author[\textbf{Rostami}]{{\bf M. A. Rostami}}
\institute[FSU Jena]{
  Chair of Advanced Computing\\
  Friedrich Schiller University Jena, Germany\\[1ex]
  \texttt{a.rostami@uni-jena.de}
}
%\date[September 2013]{September 26, 2013}

\begin{document}

%--- the titlepage frame -------------------------%
\begin{frame}[plain]
  \titlepage
\end{frame}

\begin{frame}{Structure of This Talk}
\tableofcontents
\end{frame}

\section{Motivation}
\begin{frame}{Solve a Linear Equation}
The difficult part of the solution to the most of real-world problems is to solve:
$$J \vek{y}=\vek{b},\quad \vek{y} \in \R^n, \vek{b} \in \R^n, J \in \R^{n \times n}$$
\begin{itemize}
\item In practice, these systems of linear equations are computed using iterative solvers which
need the product $J \vek{y}$ in each iteration.
\item Automatic Differentation computes the product $J \vek{y}$ without truncation error (a linear combination).
\item These iterative solvers are rarely applied in a pure fashion, but involve some sort of
preconditioning.
\end{itemize}
\end{frame}


\begin{frame}{Preconditioning}
Rather than solving the unpreconditioned system one is solving the preconditioned system
$$M^{-1} J \vek{y}= M^{-1}\vek{b},\quad M \approx J$$

Common approaches to construct the preconditioner $M$ (like ILU) are based on accessing individual
nonzero entries $J(i,j)$ of the Jacobian.

\begin{alertblock}{Access to nonzero elements}
 In general, accessing an
individual nonzero entry via automatic differentiation is as efficient as accessing a
complete column or row. In practice, an access to some individual nonzero entry is
 expensive in terms of computing time.
\end{alertblock}
\end{frame}

\section{Basics}
\begin{frame}{Sparsification}
A sparsification of $J$, \sparsify{J}, selects a 
subset of all nonzero elements of $J$ and construct a
preconditioner based on these selected nonzero elements (required elements)
\begin{itemize}
\item Block Diagonal: the pattern of the required nonzero elements is
given by the pattern of all nonzero entries within these $k\times k$ blocks on the
diagonal. If the block size $k$ does not divide the matrix order $n$, we adapt the size
of the last diagonal block to some smaller value such that the sum of all block sizes
equals $n$.
\end{itemize}
\end{frame}

\begin{frame}{Influence of Sparsification}
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{sparsify}
\end{figure}
\end{frame}

\begin{frame}{AD, Preconditioning, and Sparsification}
\begin{itemize}
  \item To perform a Jacobian-vector product $J \vek{z}$ with some vector \vek{z} in a
      iterative solver method, apply automatic differentiation with a seed matrix
      identical to that vector \vek{z}. 
  \item Choose a block size $k$ and apply the sparsification to get \sparsify{J} from
      the Jacobian~$J$. Assemble \sparsify{J} via automatic differentiation and store
      it explicitly.
  \item Construct a preconditioner $M$ from \sparsify{J} by performing an ILU(0)
      factorization on each block of~\sparsify{J}. 
\end{itemize}
\end{frame}


\begin{frame}{Problem Formulation: Block Seed}
Let $J$ be a sparse $n \times n$ Jacobian matrix with known sparsity pattern and let
\sparsify{J} denote its sparsification using $k \times k$ blocks on the diagonal of $J$.
Find a binary $n \times p$ seed matrix~$S$ with a minimal number of columns, $p$, such
that all nonzero entries of \sparsify{J} also appear in the compressed matrix $J \cdot
S$.
\end{frame}

\begin{frame}{Combinatorial Model: Bipartite Graph}
$G(V_c\times V_r,E)$
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{bip}
\end{figure}
\end{frame}

\begin{frame}{Graph Distnace-$2$ Coloring For Columns}
A coloring of $G$ is a mapping $\Phi : V_c \to {1, \dots, p}$ with the property
$\Phi(v_i)\neq \Phi(v_j)$ when $v_i$ and $v_j$ are at the distance $2$.

\begin{alertblock}{Problem}
Find a coloring $\Phi$ with a minimal number of colors.
\end{alertblock}
\end{frame}

\begin{frame}{Full Jacobian Computation}

%------------------------------------------------------------------------------------------
\begin{figure}
\centering
\includegraphics[height=0.27\textwidth]{small_jac}
\hfill
\includegraphics[height=0.27\textwidth]{full_color}
\hfill
\includegraphics[height=0.27\textwidth]{full_color_compress}
\caption{Computation of all nonzero entries.
Left: The nonzeros are displayed in black. Middle: Each column is assigned a color.
Right: Columns with the same color are computed as linear combinations.}
%
\label{f:full}
\end{figure}
%------------------------------------------------------------------------------------------
\end{frame}
\begin{frame}{Partial Jacobian Computation}
%------------------------------------------------------------------------------------------
\begin{figure}[t]
\centering
\includegraphics[height=0.27\textwidth]{partial_coloring_orig}
\hfill
\includegraphics[height=0.27\textwidth]{partial_color}
\hfill
\includegraphics[height=0.27\textwidth]{partial_color_compress}
\caption{Computation of required nonzero entries.
Left: The nonzeros are subdivided into required elements (black disks) and
nonrequired elements (black circles). Middle: Each column is assigned a color.
Right: Columns with the same
color are computed as linear combinations.}
%
\label{f:partial}
\end{figure}
%------------------------------------------------------------------------------------------

\end{frame}


\section{New Coloring Heuristics}
\begin{frame}[fragile]
\frametitle{Restricted Distance-$2$ Coloring Heuristics}
The greedy algorithm for
the distance-$2$ coloring restricted to the edge set $E_i$
for columns.
\begin{lstlisting}[mathescape]
function d2_color($G=(V_r\cup V_c,E)$,$E_i\subseteq E$)
  $\Phi\leftarrow [0\ldots 0]$
  $forbiddenColors\leftarrow [0\ldots 0]$
  for $v\in V_c$ with $\exists r\in V_r: (v,r) \in E_i$
    for $n\in N_2(v,E_i)$ with $\Phi(n) \neq 0$
        $forbiddenColors[\Phi(n)] = v$
    $\Phi(v) = \min \{ a>0:forbiddenColors[a]\neq v\}$
  return $\Phi$
\end{lstlisting}
\end{frame}
\begin{frame}[fragile]
\frametitle{New coloring heuristic}
New coloring heuristic for distance-$2$ coloring
considering the nonrequired elements.
\begin{figure}
\begin{lstlisting}[mathescape]
function d2_color_nreq($G=(V_r\cup V_c,E)$,$E_i\subseteq E$)
  $\Phi\leftarrow [0\ldots 0]$
  $forbiddenColors\leftarrow [0\ldots 0]$
  for $v\in V_c$ with $\exists r\in V_r: (v,r) \in E_i$ and $\Phi(v)=0$
    for $n\in N_2(v,E_i)$ with $\Phi(n) \neq 0$
      $forbiddenColors[\Phi(n)] = v$
    $\Phi(v) = \min \{ a>0:forbiddenColors[a]\neq v\}$

    $I_v=\{z\in V_c: z\neq v\text{ and }z\notin N_2(v) \text{ and } \Phi(z) = 0 \}$
    if $I_v\neq\emptyset$
      $maxs = \argmax_{x\in I_v} \nreq_v (x)$
      $\Phi(maxs[0]) = \Phi(v)$
  return $\Phi$
\end{lstlisting}
\end{figure}
\end{frame}
\section{Application}
\begin{frame}{Application in Geoscience}
we apply our new heuristics to a carbon sequestration example from geoscience.
The geophysics group of RWTH Aachen simulates the injection of CO$_2$ in a reservoir by a
two-phase flow model in porous media.
\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{co2_jac}
\end{figure}
\end{frame}

\begin{frame}{Convergence (Block Size = 5)}
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{jac_convergence_greedy_new_5}
\end{figure}
\end{frame}

\begin{frame}{Convergence (Block Size = 15)}
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{jac_convergence_greedy_new_15}
\end{figure}
\end{frame}


\section{A Special Case}
\section{Conclusion}
\begin{frame}{Conclusion}
\begin{itemize}
\item Automatic Differenation and Preconditioning together
\item Using partial Jacobian Computation
\item Modeling in graph language
\item Some experimental results
\end{itemize}
\end{frame}

\begin{frame}{Finish!}
\begin{center}
   \Huge \bf Thank you!
\end{center}
\end{frame}

\end{document}

